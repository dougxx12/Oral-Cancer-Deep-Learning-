{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pickle\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from utils import load_data\n",
    "import pandas as pd\n",
    "import argparse\n",
    "def load_data(in_dir, folds=None, split=None):\n",
    "    \n",
    "    if folds:\n",
    "        y_train = []\n",
    "        x_train = []\n",
    "        for f, l in zip(folds[split][\"train\"][\"x\"], folds[split][\"train\"][\"y\"]):\n",
    "            x = np.load(join(in_dir, f))\n",
    "            x_train.append(x)\n",
    "            y_train.append([l] * len(x))\n",
    "        x_train = np.vstack(x_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "\n",
    "        y_test = []\n",
    "        x_test = []\n",
    "        for f, l in zip(folds[split][\"test\"][\"x\"], folds[split][\"test\"][\"y\"]):\n",
    "            x = np.load(join(in_dir, f))\n",
    "            x_test.append(x)\n",
    "            y_test.append([l] * len(x))\n",
    "        x_test = np.vstack(x_test)\n",
    "        y_test = np.concatenate(y_test)\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    else:\n",
    "        files = glob.glob(in_dir + \"/*.npy\")\n",
    "        x = []\n",
    "        for f in files:\n",
    "            x.append(np.load(f))\n",
    "        return np.vstack(x), np.array([basename(f) for f in files])\n",
    "\n",
    "PREDS_DIR = \"predictions/\"\n",
    "N_FOLDS = 10\n",
    "N_SEEDS = 5\n",
    "DEFAULT_N_CLASSES = 4\n",
    "\n",
    "USE_PREDICTIONS = True\n",
    "LGBM_MODELS_ROOT = \"models/LGBMs\"\n",
    "DEFAULT_PREPROCESSED_ROOT = \"data/preprocessed/train/\"\n",
    "with open(\"TempDataset/10_fold_oackage.pkl\", \"rb\") as f:\n",
    "    folds = pickle.load(f)\n",
    "AUGMENTATIONS_PER_IMAGE = 50\n",
    "\n",
    "models = [\n",
    "    \"ResNet-0.5-224\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "def combine_model_scores(scores, y=None, cross_val=True):\n",
    "    if y is None:\n",
    "        return np.argmax(scores.mean(axis=(0, 2)), axis=1), scores.mean(axis=(0, 2))\n",
    "    else:\n",
    "        n_models, n_samples, n_aug, n_classes = scores.shape\n",
    "        y = np.repeat(y[:, None], n_aug, axis=1)\n",
    "        lr = LogisticRegression()\n",
    "        if cross_val:\n",
    "            pred = np.zeros((len(y), n_classes))\n",
    "            for i in range(n_samples):\n",
    "                idx = [k for k in range(len(y)) if k != i]\n",
    "                x_train = scores[:, idx, ...].transpose(1, 2, 3, 0).reshape((n_samples - 1) * n_aug,\n",
    "                                                                            n_models * n_classes)\n",
    "                y_train = y[idx].flatten()\n",
    "                x_test = scores[:, i, ...].transpose(1, 2, 0).reshape(n_aug, n_models * n_classes)\n",
    "                lr.fit(x_train, y_train)\n",
    "                pred[i] = lr.predict_proba(x_test).mean(axis=0)\n",
    "        else:\n",
    "            x = scores.transpose(1, 2, 3, 0).reshape(n_samples * n_aug, n_models * n_classes)\n",
    "            lr.fit(x, y.flatten())\n",
    "            pred = lr.predict_proba(x)\n",
    "            pred = pred.reshape(n_samples, n_aug, n_classes).mean(axis=1)\n",
    "        return np.argmax(pred, axis=1), pred\n",
    "\n",
    "    \n",
    "    \n",
    "    PREPROCESSED_ROOT = \"TempDataset\\Features\\Test\"\n",
    "    N_CLASSES = 1\n",
    "    USE_PREDICTIONS = False\n",
    "\n",
    "    blended_scores = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    scores = []\n",
    "    files = []\n",
    "    verification = defaultdict(dict)\n",
    "    for fold in range(N_FOLDS):\n",
    "        y_true_f = []\n",
    "        scores_f = []\n",
    "        files_f = []\n",
    "        for model_name in models:\n",
    "            name, scale, crop = model_name.split(\"-\")\n",
    "            scores_seeded = []\n",
    "            for seed in range(N_SEEDS):\n",
    "                if USE_PREDICTIONS:\n",
    "                    preds_file = \"lgbm_preds-{}-{}-{}-f{}-s{}.pkl\".format(name, scale, crop, fold, seed)\n",
    "                    with open(join(PREDS_DIR, name, preds_file), \"rb\") as f:\n",
    "                        preds = pickle.load(f)\n",
    "                else:\n",
    "                    model_file = \"lgbm-{}-{}-{}-f{}-s{}.pkl\".format(name, scale, crop, fold, seed)\n",
    "                    with open(join(LGBM_MODELS_ROOT, name, model_file), \"rb\") as f:\n",
    "                        model = pickle.load(f)\n",
    "                    _, _, x_test, y_test = load_data(join(PREPROCESSED_ROOT, \"{}-{}-{}\".format(name, scale, crop)),\n",
    "                                                     folds, fold)\n",
    "                    sc = model.predict(x_test)\n",
    "                    sc = sc.reshape(-1, AUGMENTATIONS_PER_IMAGE, DEFAULT_N_CLASSES)\n",
    "                    preds = {\n",
    "                        \"files\": folds[fold][\"test\"][\"x\"],\n",
    "                        \"y_true\": y_test,\n",
    "                        \"scores\": sc,\n",
    "                    }\n",
    "                n_samples, apm, _ = preds[\"scores\"].shape  \n",
    "                scores_seeded.append(preds[\"scores\"])  \n",
    "                y_true_f.append(preds[\"y_true\"][::apm])\n",
    "                files_f.append(preds[\"files\"])\n",
    "            scores_seeded = np.stack(scores_seeded) \n",
    "\n",
    "            verification[model_name][fold] = scores_seeded  \n",
    "\n",
    "            scores_f.append(scores_seeded.mean(axis=0))  \n",
    "\n",
    "        y_true_f = np.stack(y_true_f)\n",
    "        assert np.all(y_true_f == y_true_f[0])\n",
    "        files_f = np.stack(files_f)\n",
    "        assert np.all(files_f == files_f[0])\n",
    "        y_true.append(y_true_f[0])\n",
    "        files.append(files_f[0])\n",
    "\n",
    "        scores_f = np.stack(scores_f)\n",
    "        y_pred_f, scores_f = combine_model_scores(scores_f, y=None, cross_val=True)\n",
    "        y_pred.append(y_pred_f)\n",
    "        scores.append(scores_f)\n",
    "\n",
    "    if N_CLASSES == 2:\n",
    "        for fold in range(N_FOLDS):\n",
    "            # scores[i] = scores[i].reshape(-1, 2, 2).sum(axis=-1)\n",
    "            scores[fold] = scores[fold].reshape(-1, 2, 2).max(axis=-1)\n",
    "            scores[fold] = scores[fold] / scores[fold].sum(axis=-1, keepdims=True)\n",
    "            y_pred[fold][y_pred[fold] == 1] = 0\n",
    "            y_pred[fold][y_pred[fold] > 1] = 1\n",
    "            y_true[fold][y_true[fold] == 1] = 0\n",
    "            y_true[fold][y_true[fold] > 1] = 1\n",
    "\n",
    "            for model_name in models:\n",
    "                v = verification[model_name][fold]\n",
    "                N = v.shape[1]\n",
    "                v = v.reshape(N_SEEDS, N, AUGMENTATIONS_PER_IMAGE, 2, 2).max(axis=-1)\n",
    "                verification[model_name][fold] = v / v.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    all_models_folds = np.zeros((len(models), N_FOLDS))\n",
    "    for m_i, model_name in enumerate(models):\n",
    "        model_preds = []\n",
    "        for fold in range(N_FOLDS):\n",
    "            fold_preds = verification[model_name][fold].mean((0, 2)).argmax(-1)\n",
    "            model_preds.append(fold_preds)\n",
    "            all_models_folds[m_i, fold] = accuracy_score(y_true[fold], fold_preds)\n",
    "        model_acc = accuracy_score(np.concatenate(y_true), np.concatenate(model_preds))\n",
    "        print(\"{}: average across seeds: [{}]. All folds {}({:0.2})\".\n",
    "              format(model_name, \", \".join(map(lambda s: \"{:5.3}\".format(s), all_models_folds[m_i])),\n",
    "                     model_acc, all_models_folds[m_i].std()))\n",
    "    print()\n",
    "    print(\"Std across models: [{}]. All folds {:5.3}\".\n",
    "          format(\", \".join(map(lambda s: \"{:5.3}\".format(s), all_models_folds.std(0))), all_models_folds.std(0).mean()))\n",
    "    acc_folded = np.array([accuracy_score(y_t, y_p) for y_t, y_p in zip(y_true, y_pred)])  # y_true, y_pred contain folds\n",
    "    acc_blend = accuracy_score(np.concatenate(y_true), np.concatenate(y_pred))\n",
    "    print(\"Blended model: [{}], mean {:5.3}, std {:5.3}\".format(\", \".join(map(lambda s: \"{:5.3}\".format(s), acc_folded)),\n",
    "                                                                acc_blend, acc_folded.std()))\n",
    "\n",
    "    # Dump crossvalidation stats\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    scores = np.concatenate(scores)\n",
    "    files = np.concatenate(files)\n",
    "\n",
    "    if N_CLASSES == 2:\n",
    "        with open(\"data/roc_scores.pkl\", \"wb\") as f:\n",
    "            pickle.dump((scores, y_true), f)\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
