{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"TempDataset\\normal\\*.jpeg\" # the dataset file or root folder path.\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os.path import basename, join\n",
    "\n",
    "import glob\n",
    "files = np.array([ f for f in glob.glob(\"TempDataset\\cancer\\*.jpeg\")])\n",
    "for file in files :\n",
    "    f = basename(file)\n",
    "    myimage = Image.open(file)\n",
    "    #myimage = myimage.rotate(180)\n",
    "    #r180 = \"myrot_180_\" + f ;\n",
    "    #sf = \"TempDataset\\cancer\\\\\"+ r180\n",
    "    #myimage.save(sf)\n",
    "    #myimage = np.fliplr(myimage)\n",
    "    #myimage = Image.fromarray(myimage)\n",
    "    #r180 = \"fliplr_\" + f ;\n",
    "    #sf = \"TempDataset\\cancer\\\\\"+ r180\n",
    "    #myimage.save(sf)\n",
    "    x_shift = 250\n",
    "    y_shift = 150\n",
    "    a = 1\n",
    "    b = 0\n",
    "    c = x_shift #left/right (i.e. 5/-5)\n",
    "    d = 0\n",
    "    e = 1\n",
    "    g = y_shift #up/down (i.e. 5/-5)\n",
    "    translate = myimage.transform(myimage.size, Image.AFFINE, (a, b, c, d, e, f))\n",
    "    size = (translate.size[0] - x_shift, translate.size[1] - y_shift)\n",
    "    translate = translate.transform(size, Image.EXTENT, (0, 0, size[0], size[1]))\n",
    "    r180 = \"xy250x150_\" + f\n",
    "    sf = \"TempDataset\\cancer\\\\\"+ r180\n",
    "    translate.save(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'E:\\\\Projects\\\\HolisticClassification\\\\TempDataset\\normal\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7b13a05f19da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-4311b4893f83>\u001b[0m in \u001b[0;36mread_images\u001b[1;34m(dataset_path, mode, batch_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'folder'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'E:\\\\Projects\\\\HolisticClassification\\\\TempDataset\\normal\\\\'"
     ]
    }
   ],
   "source": [
    "read_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#taken from the several iciar 2018 implementations\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from os.path import basename, join, exists\n",
    "from os import makedirs\n",
    "#from threaded_generator import threaded_generator\n",
    "from time import time\n",
    "import sys\n",
    "np.random.seed(13)\n",
    "\n",
    "PATCH_SIZES = [224]\n",
    "SCALES = [0.5]\n",
    "\n",
    "DEFAULT_INPUT_DIR = \"data/train\"\n",
    "DEFAULT_PREPROCESSED_ROOT = \"data/preprocessed/train\"\n",
    "\n",
    "PATCHES_PER_IMAGE = 20\n",
    "AUGMENTATIONS_PER_IMAGE = 50\n",
    "COLOR_LO = 0.7\n",
    "COLOR_HI = 1.3\n",
    "BATCH_SIZE = 16     # decrease if necessary\n",
    "\n",
    "NUM_CACHED = 160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_staining(img):\n",
    "   \n",
    "    Io = 240\n",
    "    beta = 0.15\n",
    "    alpha = 1\n",
    "    HERef = np.array([[0.5626, 0.2159],\n",
    "                      [0.7201, 0.8012],\n",
    "                      [0.4062, 0.5581]])\n",
    "    maxCRef = np.array([1.9705, 1.0308])\n",
    "\n",
    "    h, w, c = img.shape\n",
    "    img = img.reshape(h * w, c)\n",
    "    OD = -np.log((img.astype(\"uint16\") + 1) / Io)\n",
    "    ODhat = OD[(OD >= beta).all(axis=1)]\n",
    "    if ODhat.shape[0] < 0 or ODhat.shape[1]<0 :\n",
    "        return\n",
    "    W, V = np.linalg.eig(np.cov(ODhat, rowvar=False))\n",
    "\n",
    "    Vec = -V.T[:2][::-1].T  \n",
    "    That = np.dot(ODhat, Vec)\n",
    "    phi = np.arctan2(That[:, 1], That[:, 0])\n",
    "    minPhi = np.percentile(phi, alpha)\n",
    "    maxPhi = np.percentile(phi, 100 - alpha)\n",
    "    vMin = np.dot(Vec, np.array([np.cos(minPhi), np.sin(minPhi)]))\n",
    "    vMax = np.dot(Vec, np.array([np.cos(maxPhi), np.sin(maxPhi)]))\n",
    "    if vMin[0] > vMax[0]:\n",
    "        HE = np.array([vMin, vMax])\n",
    "    else:\n",
    "        HE = np.array([vMax, vMin])\n",
    "\n",
    "    HE = HE.T\n",
    "    Y = OD.reshape(h * w, c).T\n",
    "\n",
    "    C = np.linalg.lstsq(HE, Y)\n",
    "    maxC = np.percentile(C[0], 99, axis=1)\n",
    "\n",
    "    C = C[0] / maxC[:, None]\n",
    "    C = C * maxCRef[:, None]\n",
    "    Inorm = Io * np.exp(-np.dot(HERef, C))\n",
    "    Inorm = Inorm.T.reshape(h, w, c).clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "    return Inorm\n",
    "\n",
    "\n",
    "def hematoxylin_eosin_aug(img, low=0.7, high=1.3, seed=None):\n",
    "    D = np.array([[1.88, -0.07, -0.60],\n",
    "                  [-1.02, 1.13, -0.48],\n",
    "                  [-0.55, -0.13, 1.57]])\n",
    "    M = np.array([[0.65, 0.70, 0.29],\n",
    "                  [0.07, 0.99, 0.11],\n",
    "                  [0.27, 0.57, 0.78]])\n",
    "    Io = 240\n",
    "\n",
    "    h, w, c = img.shape\n",
    "    OD = -np.log10((img.astype(\"uint16\") + 1) / Io)\n",
    "    C = np.dot(D, OD.reshape(h * w, c).T).T\n",
    "    r = np.ones(3)\n",
    "    r[:2] = np.random.RandomState(seed).uniform(low=low, high=high, size=2)\n",
    "    img_aug = np.dot(C, M) * r\n",
    "\n",
    "    img_aug = Io * np.exp(-img_aug * np.log(10)) - 1\n",
    "    img_aug = img_aug.reshape(h, w, c).clip(0, 255).astype(\"uint8\")\n",
    "    return img_aug\n",
    "\n",
    "def zoom_aug(img, zoom_var, seed=None):\n",
    "    scale = np.random.RandomState(seed).uniform(low=1 / zoom_var, high=zoom_var)\n",
    "    resized_img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    return resized_img\n",
    "\n",
    "def get_crops(img, size, n, seed=None):\n",
    "    h, w, c = img.shape\n",
    "    assert all([size < h, size < w])\n",
    "    crops = []\n",
    "    for _ in range(n):\n",
    "        top = np.random.randint(low=0, high=h - size + 1)\n",
    "        left = np.random.randint(low=0, high=w - size + 1)\n",
    "        crop = img[top: top + size, left: left + size].copy()\n",
    "        crop = np.rot90(crop, np.random.randint(low=0, high=4))\n",
    "        if np.random.random() > 0.5:\n",
    "            crop = np.flipud(crop)\n",
    "        if np.random.random() > 0.5:\n",
    "            crop = np.fliplr(crop)\n",
    "        crops.append(crop)\n",
    "\n",
    "    crops = np.stack(crops)\n",
    "    assert crops.shape == (n, size, size, c)\n",
    "    return crops\n",
    "\n",
    "\n",
    "def get_crops_free(img, size, n, seed=None):\n",
    "    h, w, c = img.shape\n",
    "    assert all([size < h, size < w])\n",
    "    d = int(np.ceil(size / np.sqrt(2)))\n",
    "    crops = []\n",
    "    for _ in range(n):\n",
    "        center_y = np.random.randint(low=0, high=h - size + 1) + size // 2\n",
    "        center_x = np.random.randint(low=0, high=w - size + 1) + size // 2\n",
    "        m = min(center_y, center_x, h - center_y, w - center_x)\n",
    "        if m < d:\n",
    "            max_angle = np.pi / 4 - np.arccos(m / d)\n",
    "            top = center_y - m\n",
    "            left = center_x - m\n",
    "            precrop = img[top: top + 2 * m, left: left + 2 * m]\n",
    "        else:\n",
    "            max_angle = np.pi / 4\n",
    "            top = center_y - d\n",
    "            left = center_x - d\n",
    "            precrop = img[top: top + 2 * d, left: left + 2 * d]\n",
    "\n",
    "        precrop = np.rot90(precrop, np.random.randint(low=0, high=4))\n",
    "        angle = np.random.uniform(low=-max_angle, high=max_angle)\n",
    "        precrop = ndimage.rotate(precrop, angle * 180 / np.pi, reshape=False)\n",
    "\n",
    "        precrop_h, precrop_w, _ = precrop.shape\n",
    "        top = (precrop_h - size) // 2\n",
    "        left = (precrop_w - size) // 2\n",
    "        crop = precrop[top: top + size, left: left + size]\n",
    "\n",
    "        if np.random.random() > 0.5:\n",
    "            crop = np.flipud(crop)\n",
    "        if np.random.random() > 0.5:\n",
    "            crop = np.fliplr(crop)\n",
    "        crops.append(crop)\n",
    "\n",
    "    crops = np.stack(crops)\n",
    "    assert crops.shape == (n, size, size, c)\n",
    "    return crops\n",
    "\n",
    "\n",
    "def norm_pool(features, p=3):\n",
    "    return np.power(np.power(features, p).mean(axis=0), 1/p)\n",
    "\n",
    "\n",
    "def encode(crops, model):\n",
    "    features = model.predict(crops)\n",
    "    pooled_features = norm_pool(features)\n",
    "    return pooled_features\n",
    "\n",
    "\n",
    "def process_image(image_file):\n",
    "    img = cv2.imread(image_file)\n",
    "    if SCALE != 1:\n",
    "        img = cv2.resize(img, None, fx=SCALE, fy=SCALE, interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_norm = normalize_staining(img)\n",
    "    if(img_norm == NULL)\n",
    "    for _ in range(AUGMENTATIONS_PER_IMAGE):\n",
    "        img_aug = hematoxylin_eosin_aug(img_norm, low=COLOR_LO, high=COLOR_HI)\n",
    "        single_image_crops = get_crops(img_aug, PATCH_SZ, PATCHES_PER_IMAGE)\n",
    "        yield single_image_crops\n",
    "\n",
    "\n",
    "def crops_gen(file_list):\n",
    "    for i, (image_file, output_file) in enumerate(file_list):\n",
    "        print(\"Crops generator:\", i + 1,image_file,output_file)\n",
    "        for crops in process_image(image_file):\n",
    "            yield crops, output_file\n",
    "\n",
    "\n",
    "def features_gen(crops_and_output_file, model):\n",
    "    #print(\"features gen\");\n",
    "    ts = time()\n",
    "    current_file = None\n",
    "    pooled_features = []\n",
    "    i = 0\n",
    "    for j, (crops, output_file) in enumerate(crops_and_output_file):\n",
    "        #print(\"cropping\",j)\n",
    "        #print(crops, output_file)\n",
    "        if current_file is None:\n",
    "            current_file = output_file\n",
    "        features = encode(crops, model)\n",
    "        if output_file == current_file:\n",
    "            pooled_features.append(features)\n",
    "        else:\n",
    "            np.save(current_file, np.stack(pooled_features))\n",
    "            pooled_features = [features]\n",
    "            current_file = output_file\n",
    "            average_time = int((time() - ts) / (i + 1))\n",
    "            print(\"Feature generator: {}, {} sec/image.\".format(i + 1, average_time))\n",
    "            i += 1\n",
    "    if len(pooled_features) > 0:\n",
    "        np.save(current_file, np.stack(pooled_features))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-aaf1918ccb77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmyimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmyimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimg_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhematoxylin_eosin_aug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mimg_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_aug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mr180\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"img_aug0.1x0.3\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-5cfb8b719f25>\u001b[0m in \u001b[0;36mhematoxylin_eosin_aug\u001b[1;34m(img, low, high, seed)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mOD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"uint16\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mIo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#read_images_convert_to_jpeg()\n",
    "files = np.array([ f for f in glob.glob(\"TempDataset\\cancer\\*.jpeg\")])\n",
    "for file in files :\n",
    "    f = basename(file)\n",
    "    myimage = cv2.imread(file)\n",
    "    myimage = cv2.cvtColor(myimage, cv2.COLOR_BGR2RGB)\n",
    "    img_aug = hematoxylin_eosin_aug(myimage, low=0.1, high=0.3)\n",
    "    img_aug = Image.fromarray(img_aug)\n",
    "    r180 = \"img_aug0.1x0.3\" + f\n",
    "    sf = \"TempDataset\\cancer\\\\\"+ r180\n",
    "    img_aug.save(sf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3236\n"
     ]
    }
   ],
   "source": [
    "files = np.array([basename(f) for f in glob.glob(\"TempDataset\\cancernormal\\\\\")])\n",
    "i = 2435;\n",
    "for filename in os.listdir(\"TempDataset\\cancernormal\\\\\"): \n",
    "        dst =\"normal_\" + str(i)+\".jpeg\"\n",
    "        src =\"TempDataset\\cancernormal\\\\\"+ filename \n",
    "        dst =\"TempDataset\\Train\\\\\"+ dst \n",
    "        i+=1  \n",
    "        # rename() function will \n",
    "        # rename all the files \n",
    "        os.rename(src, dst) \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "class ResNet:\n",
    "    __name__ = \"ResNet\"\n",
    "\n",
    "    def __init__(self, batch_size=16):\n",
    "        self.model = tf.contrib.keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', pooling=\"avg\")\n",
    "        self.batch_size = batch_size\n",
    "        self.data_format =  tf.keras.backend.image_data_format()\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.data_format == \"channels_first\":\n",
    "            x = x.transpose(0, 3, 1, 2)\n",
    "        x = tf.contrib.keras.applications.resnet50.preprocess_input(x.astype(tf.keras.backend.floatx()))\n",
    "        return self.model.predict(x, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALE: 0.5\n",
      "NN_MODEL: ResNet\n",
      "PATCH_SZ: 224\n",
      "Crops generator: 1 TempDataset\\Train\\normal_2549.jpeg TempDataset\\Train\\normal_2549.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:34: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crops generator: 2 TempDataset\\Train\\normal_2550.jpeg TempDataset\\Train\\normal_2550.npy\n",
      "Feature generator: 1, 387 sec/image.\n",
      "Crops generator: 3 TempDataset\\Train\\normal_2551.jpeg TempDataset\\Train\\normal_2551.npy\n",
      "Feature generator: 2, 385 sec/image.\n",
      "Crops generator: 4 TempDataset\\Train\\normal_2552.jpeg TempDataset\\Train\\normal_2552.npy\n",
      "Feature generator: 3, 384 sec/image.\n",
      "Crops generator: 5 TempDataset\\Train\\normal_2553.jpeg TempDataset\\Train\\normal_2553.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\lib\\function_base.py:356: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "E:\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\lib\\function_base.py:2326: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\lib\\function_base.py:2326: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-4cdb8e083a58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mcrops_and_output_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrops_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m#crops_and_output_file_ = threaded_generator(crops_and_output_file, num_cached=NUM_CACHED)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mfeatures_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrops_and_output_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-d4e2d6d6411d>\u001b[0m in \u001b[0;36mfeatures_gen\u001b[1;34m(crops_and_output_file, model)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mpooled_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcrops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrops_and_output_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;31m#print(\"cropping\",j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m#print(crops, output_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-d4e2d6d6411d>\u001b[0m in \u001b[0;36mcrops_gen\u001b[1;34m(file_list)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Crops generator:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mcrops\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mcrops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-d4e2d6d6411d>\u001b[0m in \u001b[0;36mprocess_image\u001b[1;34m(image_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[0mimg_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_staining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUGMENTATIONS_PER_IMAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-d4e2d6d6411d>\u001b[0m in \u001b[0;36mnormalize_staining\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mODhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mODhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mODhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1262\u001b[1;33m     \u001b[0m_assertFinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1263\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assertFinite\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Array must not contain infs or NaNs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_isEmpty2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import basename, join, exists\n",
    "DATASET_PATH = 'TempDataset\\Train\\\\' # the dataset file or root folder path.\n",
    "\n",
    "\n",
    "NUM_CACHED = 160\n",
    "NN_MODELS = [ResNet]\n",
    "for SCALE in SCALES:\n",
    "        print(\"SCALE:\", SCALE)\n",
    "        for NN_MODEL in NN_MODELS:\n",
    "            print(\"NN_MODEL:\", NN_MODEL.__name__)\n",
    "            for PATCH_SZ in PATCH_SIZES:\n",
    "                print(\"PATCH_SZ:\", PATCH_SZ)\n",
    "                model = NN_MODEL(batch_size=BATCH_SIZE)\n",
    "                files = np.array([f for f in glob.glob(DATASET_PATH+\"*.jpeg\")])\n",
    "\n",
    "                output_files =[f.replace(\"jpeg\", \"npy\") for f in files]\n",
    "                \n",
    "                file_list = zip(files, output_files)\n",
    "                crops_and_output_file = crops_gen(file_list)\n",
    "                #crops_and_output_file_ = threaded_generator(crops_and_output_file, num_cached=NUM_CACHED)\n",
    "                features_gen(crops_and_output_file, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
