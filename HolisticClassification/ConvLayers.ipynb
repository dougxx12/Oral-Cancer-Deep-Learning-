{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time \n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#train data class normal 38 class bad 280 \n",
    "#test data class normal 10 class bad 20\n",
    "import utils\n",
    "MODE = 'folder' # or 'file', if you choose a plain text file (see above).\n",
    "DATASET_PATH = 'E:\\Projects\\HolisticClassification\\Dataset' # the dataset file or root folder path.\n",
    "TEST_DATASET_PATH = 'E:\\Projects\\HolisticClassification\\Dataset\\Test'\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Image Parameters\n",
    "N_CLASSES = 2 # CHANGE HERE, total number of classes\n",
    "IMG_HEIGHT = 32 # CHANGE HERE, the image height to be resized to\n",
    "IMG_WIDTH = 32 # CHANGE HERE, the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n",
    "\n",
    "def read_images_convert_to_jpeg(dataset_path = DATASET_PATH, mode = MODE, batch_size = BATCH_SIZE):\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'folder':\n",
    "        label = 0\n",
    "        classes = [f.path for f in os.scandir(dataset_path) if f.is_dir() ] \n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "            for sample in walk[2]:\n",
    "                if sample.endswith('.bmp') or sample.endswith('.BMP'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "    for image_loc in imagepaths:\n",
    "        print(image_loc)\n",
    "        img = Image.open(image_loc)\n",
    "        new_img = img.resize( (IMG_HEIGHT, IMG_HEIGHT) )\n",
    "        save_loc = os.path.splitext(image_loc)[0] + \".jpeg\"\n",
    "        print(save_loc)\n",
    "        new_img.save( save_loc, 'jpeg')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_images_convert_to_jpeg(dataset_path = TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"data/Reshape_316:0\", shape=(316, 3072), dtype=float32) (316, 2)\n",
      "Tensor(\"data/Reshape_347:0\", shape=(30, 3072), dtype=float32) (30, 2)\n",
      "(tf.float32, tf.float64) (TensorShape([Dimension(None), Dimension(3072)]), TensorShape([Dimension(None), Dimension(2)]))\n",
      "INFO:tensorflow:Summary name histogram loss is illegal; using histogram_loss instead.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/convnet_layers\\mnist-convnet-158\n",
      "Loss at step 159: 0.8815603256225586\n",
      "Loss at step 179: 0.38655826449394226\n",
      "Loss at step 199: 0.6242591142654419\n",
      "Loss at step 219: 0.9529273509979248\n",
      "Average loss at epoch 0: 0.4015271011504191\n",
      "Took: 5.125051736831665 seconds\n",
      "Accuracy at epoch 0: 0.6666666666666666 \n",
      "Took: 0.09373354911804199 seconds\n",
      "Loss at step 239: 0.6845662593841553\n",
      "Loss at step 259: 0.7041158676147461\n",
      "Loss at step 279: 0.6553569436073303\n",
      "Loss at step 299: 0.007219100836664438\n",
      "Average loss at epoch 1: 0.34952473563519365\n",
      "Took: 4.625049114227295 seconds\n",
      "Accuracy at epoch 1: 0.6666666666666666 \n",
      "Took: 0.046875953674316406 seconds\n",
      "Loss at step 319: 0.9735316038131714\n",
      "Loss at step 339: 0.5748109817504883\n",
      "Loss at step 359: 1.0261988639831543\n",
      "Loss at step 379: 8.314774277096149e-06\n",
      "Average loss at epoch 2: 0.3899995674661125\n",
      "Took: 4.515689373016357 seconds\n",
      "Accuracy at epoch 2: 0.6666666666666666 \n",
      "Took: 0.0468592643737793 seconds\n",
      "Loss at step 399: 0.09594529122114182\n",
      "Loss at step 419: 0.2796567678451538\n",
      "Loss at step 439: 0.08305737376213074\n",
      "Loss at step 459: 1.110347032546997\n",
      "Average loss at epoch 3: 0.39105002991147814\n",
      "Took: 4.437560081481934 seconds\n",
      "Accuracy at epoch 3: 0.6666666666666666 \n",
      "Took: 0.031238079071044922 seconds\n",
      "Loss at step 479: 0.2641623318195343\n",
      "Loss at step 499: 0.9249729514122009\n",
      "Loss at step 519: 0.18752633035182953\n",
      "Loss at step 539: 0.6244742274284363\n",
      "Average loss at epoch 4: 0.4010432429056868\n",
      "Took: 4.281295299530029 seconds\n",
      "Accuracy at epoch 4: 0.6666666666666666 \n",
      "Took: 0.04689741134643555 seconds\n",
      "Loss at step 559: 0.5565209984779358\n",
      "Loss at step 579: 1.1232235431671143\n",
      "Loss at step 599: 0.09387221932411194\n",
      "Loss at step 619: 0.25078892707824707\n",
      "Average loss at epoch 5: 0.48386385363545154\n",
      "Took: 4.656296968460083 seconds\n",
      "Accuracy at epoch 5: 0.6666666666666666 \n",
      "Took: 0.04685640335083008 seconds\n",
      "Loss at step 639: 0.9294570088386536\n",
      "Loss at step 659: 0.6539392471313477\n",
      "Loss at step 679: 0.1119992658495903\n",
      "Loss at step 699: 0.1615637242794037\n",
      "Average loss at epoch 6: 0.400400624575117\n",
      "Took: 4.750051498413086 seconds\n",
      "Accuracy at epoch 6: 0.6666666666666666 \n",
      "Took: 0.03126049041748047 seconds\n",
      "Loss at step 719: 0.5507906675338745\n",
      "Loss at step 739: 0.6379963159561157\n",
      "Loss at step 759: 0.022014811635017395\n",
      "Loss at step 779: 0.0011887492146342993\n",
      "Average loss at epoch 7: 0.3772332279285699\n",
      "Took: 4.500054597854614 seconds\n",
      "Accuracy at epoch 7: 0.6666666666666666 \n",
      "Took: 0.031234025955200195 seconds\n",
      "Loss at step 799: 0.6768510341644287\n",
      "Loss at step 819: 0.32739314436912537\n",
      "Loss at step 839: 0.10830965638160706\n",
      "Loss at step 859: 0.07247083634138107\n",
      "Average loss at epoch 8: 0.38649658158515826\n",
      "Took: 4.625066757202148 seconds\n",
      "Accuracy at epoch 8: 0.6666666666666666 \n",
      "Took: 0.046858787536621094 seconds\n",
      "Loss at step 879: 0.45946285128593445\n",
      "Loss at step 899: 1.7181302309036255\n",
      "Loss at step 919: 0.0540078803896904\n",
      "Loss at step 939: 0.07762648165225983\n",
      "Average loss at epoch 9: 0.33812674660754355\n",
      "Took: 4.515689134597778 seconds\n",
      "Accuracy at epoch 9: 0.6666666666666666 \n",
      "Took: 0.04687190055847168 seconds\n"
     ]
    }
   ],
   "source": [
    "#taken from stanford tensorflow tutorial for cnn\n",
    "\n",
    "def read_images(dataset_path = DATASET_PATH, mode = MODE, batch_size = BATCH_SIZE):\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'folder':\n",
    "        label = 0\n",
    "        classes = [f.path for f in os.scandir(DATASET_PATH) if f.is_dir() ] \n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "            for sample in walk[2]:\n",
    "                if sample.endswith('.jpeg') or sample.endswith('.JPEG'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "    resized_image_array=[]\n",
    "\n",
    "    for image_loc in imagepaths:\n",
    "        image_decoded = tf.image.decode_jpeg(tf.gfile.FastGFile(image_loc, 'rb').read(),channels=0)\n",
    "        resized_image = tf.reshape(tf.image.resize_images(image_decoded, [IMG_HEIGHT,IMG_HEIGHT]),[1,IMG_HEIGHT*IMG_HEIGHT*CHANNELS])\n",
    "        resized_image_array.append(resized_image)\n",
    "    resized_image_array = tf.reshape(tf.stack(resized_image_array),[len(imagepaths),IMG_HEIGHT*IMG_HEIGHT*CHANNELS])\n",
    "    # Normalize\n",
    "    #image = image * 1.0/127.5 - 1.0\n",
    "    labels = np.asarray(labels)\n",
    "    new_labels = np.zeros((len(imagepaths), N_CLASSES))\n",
    "    new_labels[np.arange(len(imagepaths)), labels] = 1\n",
    "    image = tf.convert_to_tensor(resized_image_array,dtype=tf.float32)\n",
    "    \n",
    "    print(image, new_labels.shape)\n",
    "    train_data = (image,new_labels)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "    train_data = train_data.shuffle(128)\n",
    "    train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "    # Create batches\n",
    "   # X, Y = tf.train.batch([image, label], batch_size=batch_size, capacity=batch_size * 8, num_threads=4)\n",
    "    return train_data\n",
    "\n",
    "def read_test_images(dataset_path = TEST_DATASET_PATH, mode = MODE, batch_size = BATCH_SIZE):\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'folder':\n",
    "        label = 0\n",
    "        classes = [f.path for f in os.scandir(TEST_DATASET_PATH) if f.is_dir() ] \n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "            for sample in walk[2]:\n",
    "                if sample.endswith('.jpeg') or sample.endswith('.JPEG'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "    resized_image_array=[]\n",
    "\n",
    "    for image_loc in imagepaths:\n",
    "        image_decoded = tf.image.decode_jpeg(tf.gfile.FastGFile(image_loc, 'rb').read(),channels=0)\n",
    "        resized_image = tf.reshape(tf.image.resize_images(image_decoded, [IMG_HEIGHT,IMG_HEIGHT]),[1,IMG_HEIGHT*IMG_HEIGHT*CHANNELS])\n",
    "        resized_image_array.append(resized_image)\n",
    "    resized_image_array = tf.reshape(tf.stack(resized_image_array),[len(imagepaths),IMG_HEIGHT*IMG_HEIGHT*CHANNELS])\n",
    "    # Normalize\n",
    "    #image = image * 1.0/127.5 - 1.0\n",
    "    labels = np.asarray(labels)\n",
    "    new_labels = np.zeros((len(imagepaths), N_CLASSES))\n",
    "    new_labels[np.arange(len(imagepaths)), labels] = 1\n",
    "    image = tf.convert_to_tensor(resized_image_array,dtype=tf.float32)\n",
    "    \n",
    "    print(image, new_labels.shape)\n",
    "    test_data = (image,new_labels)\n",
    "    test_data = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "    test_data = test_data.batch(BATCH_SIZE)\n",
    "\n",
    "    # Create batches\n",
    "   # X, Y = tf.train.batch([image, label], batch_size=batch_size, capacity=batch_size * 8, num_threads=4)\n",
    "    return test_data\n",
    "\n",
    "\n",
    "class ConvNet(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.keep_prob = tf.constant(0.75)\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, \n",
    "                                trainable=False, name='global_step')\n",
    "        self.n_classes = 2\n",
    "        self.skip_step = 20\n",
    "        self.n_test = 30\n",
    "        self.training=False\n",
    "\n",
    "    def get_data(self):\n",
    "        with tf.name_scope('data'):          \n",
    "            train_data = read_images()\n",
    "            test_data = read_test_images()\n",
    "            iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                                   train_data.output_shapes)\n",
    "            print(train_data.output_types, train_data.output_shapes)\n",
    "            img, self.label = iterator.get_next()\n",
    "            self.img = tf.reshape(img, shape=[-1, IMG_WIDTH, IMG_HEIGHT, CHANNELS])\n",
    "            # reshape the image to make it work with tf.nn.conv2d\n",
    "\n",
    "            self.train_init = iterator.make_initializer(train_data)  # initializer for train_data\n",
    "            self.test_init = iterator.make_initializer(test_data)    # initializer for test_data\n",
    "\n",
    "    def inference(self):\n",
    "        conv1 = tf.layers.conv2d(inputs=self.img,\n",
    "                                  filters=32,\n",
    "                                  kernel_size=[5, 5],\n",
    "                                  padding='SAME',\n",
    "                                  activation=tf.nn.relu,\n",
    "                                  name='conv1')\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                        pool_size=[2, 2], \n",
    "                                        strides=2,\n",
    "                                        name='pool1')\n",
    "\n",
    "        conv2 = tf.layers.conv2d(inputs=pool1,\n",
    "                                  filters=64,\n",
    "                                  kernel_size=[5, 5],\n",
    "                                  padding='SAME',\n",
    "                                  activation=tf.nn.relu,\n",
    "                                  name='conv2')\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                        pool_size=[2, 2], \n",
    "                                        strides=2,\n",
    "                                        name='pool2')\n",
    "\n",
    "        feature_dim = pool2.shape[1] * pool2.shape[2] * pool2.shape[3]\n",
    "        pool2 = tf.reshape(pool2, [-1, feature_dim])\n",
    "        fc = tf.layers.dense(pool2, 128, activation=tf.nn.relu, name='fc')\n",
    "        dropout = tf.layers.dropout(fc, \n",
    "                                    self.keep_prob, \n",
    "                                    training=self.training, \n",
    "                                    name='dropout')\n",
    "        self.logits = tf.layers.dense(dropout, self.n_classes, name='logits')\n",
    "\n",
    "    def loss(self):\n",
    "        '''\n",
    "        define loss function\n",
    "        use softmax cross entropy with logits as the loss function\n",
    "        compute mean cross entropy, softmax is applied internally\n",
    "        '''\n",
    "        # \n",
    "        with tf.name_scope('loss'):\n",
    "            entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.label, logits=self.logits)\n",
    "            self.loss = tf.reduce_mean(entropy, name='loss')\n",
    "    \n",
    "    def optimize(self):\n",
    "        '''\n",
    "        Define training op\n",
    "        using Adam Gradient Descent to minimize cost\n",
    "        '''\n",
    "        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, \n",
    "                                                global_step=self.gstep)\n",
    "\n",
    "    def summary(self):\n",
    "        '''\n",
    "        Create summaries to write on TensorBoard\n",
    "        '''\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('accuracy', self.accuracy)\n",
    "            tf.summary.histogram('histogram loss', self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    def eval(self):\n",
    "        '''\n",
    "        Count the number of right predictions in a batch\n",
    "        '''\n",
    "        with tf.name_scope('predict'):\n",
    "            preds = tf.nn.softmax(self.logits)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.label, 1))\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "    def build(self):\n",
    "        '''\n",
    "        Build the computation graph\n",
    "        '''\n",
    "        self.get_data()\n",
    "        self.inference()\n",
    "        self.loss()\n",
    "        self.optimize()\n",
    "        self.eval()\n",
    "        self.summary()\n",
    "\n",
    "    def train_one_epoch(self, sess, saver, init, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        sess.run(init) \n",
    "        self.training = True\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l, summaries = sess.run([self.opt, self.loss, self.summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                if (step + 1) % self.skip_step == 0:\n",
    "                    print('Loss at step {0}: {1}'.format(step, l))\n",
    "                step += 1\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        saver.save(sess, 'checkpoints/convnet_layers/mnist-convnet', step)\n",
    "        print('Average loss at epoch {0}: {1}'.format(epoch, total_loss/n_batches))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        return step\n",
    "\n",
    "    def eval_once(self, sess, init, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        sess.run(init)\n",
    "        self.training = False\n",
    "        total_correct_preds = 0\n",
    "        try:\n",
    "            while True:\n",
    "                accuracy_batch, summaries = sess.run([self.accuracy, self.summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                total_correct_preds += accuracy_batch\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Accuracy at epoch {0}: {1} '.format(epoch, total_correct_preds/self.n_test))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        '''\n",
    "        The train function alternates between training one epoch and evaluating\n",
    "        '''\n",
    "        utils.safe_mkdir('checkpoints')\n",
    "        utils.safe_mkdir('checkpoints/convnet_layers')\n",
    "        writer = tf.summary.FileWriter('./graphs/convnet_layers', tf.get_default_graph())\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/convnet_layers/checkpoint'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            step = self.gstep.eval()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                step = self.train_one_epoch(sess, saver, self.train_init, writer, epoch, step)\n",
    "                self.eval_once(sess, self.test_init, writer, epoch, step)\n",
    "        writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = ConvNet()\n",
    "    model.build()\n",
    "    model.train(n_epochs=10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Achieved 66.67 % accuracy with [conv-pool-conv-pool-fc-softmax] architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
